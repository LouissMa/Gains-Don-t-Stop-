{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d64224",
   "metadata": {},
   "source": [
    "1.不含模型参数的自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8274a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -1.,  0.,  1.,  2.])\n",
      "输出均值: 2.1827872842550278e-09\n"
     ]
    }
   ],
   "source": [
    "#基础实现\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CenteredLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x - x.mean()\n",
    "## 实例化并使用\n",
    "layer = CenteredLayer()\n",
    "result = layer(torch.tensor([1, 2, 3, 4, 5], dtype=torch.float))\n",
    "print(result)\n",
    "\n",
    "# 将自定义层集成到Sequential中\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(8, 128),    # 有参数的线性层\n",
    "    CenteredLayer()        # 无参数的自定义层\n",
    ")\n",
    "\n",
    "# 前向传播\n",
    "y = net(torch.rand(4, 8))  # 输入: 4个样本，每个8维特征\n",
    "print(f\"输出均值: {y.mean().item()}\")  # 应该接近0，因为减去了均值\n",
    "# 输出: 输出均值: -x.xxxxe-xx (接近0的很小数值)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58140e36",
   "metadata": {},
   "source": [
    "2.含模型参数的⾃自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c98920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (1): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (2): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (3): Parameter containing: [torch.float32 of size 4x1]\n",
      "  )\n",
      ")\n",
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n",
      "linear1 输出: tensor([[-1.9645, -1.6549, -2.6726, -3.7488]], grad_fn=<MmBackward0>)\n",
      "linear2 输出: tensor([[1.6141]], grad_fn=<MmBackward0>)\n",
      "linear3 输出: tensor([[1.5407, 2.6891]], grad_fn=<MmBackward0>)\n",
      "Sequential(\n",
      "  (0): MyDictDense(\n",
      "    (params): ParameterDict(\n",
      "        (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "        (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "        (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "    )\n",
      "  )\n",
      "  (1): MyListDense(\n",
      "    (params): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 4x4]\n",
      "        (1): Parameter containing: [torch.float32 of size 4x4]\n",
      "        (2): Parameter containing: [torch.float32 of size 4x4]\n",
      "        (3): Parameter containing: [torch.float32 of size 4x1]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential 输出: tensor([[-17.7722]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyListDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        # 使用ParameterList管理参数列表\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i])  # 矩阵乘法\n",
    "        return x\n",
    "\n",
    "net = MyListDense()\n",
    "print(net)\n",
    "\n",
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        # 使用ParameterDict管理参数字典\n",
    "        self.params = nn.ParameterDict({\n",
    "            'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "            'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))})  # 新增参数\n",
    "    \n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])  # 根据选择使用不同的参数\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)\n",
    "\n",
    "x = torch.ones(1, 4)\n",
    "print(\"linear1 输出:\", net(x, 'linear1'))\n",
    "print(\"linear2 输出:\", net(x, 'linear2')) \n",
    "print(\"linear3 输出:\", net(x, 'linear3'))\n",
    "\n",
    "# 在模型序列中使用自定义层\n",
    "net = nn.Sequential(\n",
    "    MyDictDense(),\n",
    "    MyListDense(),\n",
    ")\n",
    "print(net)\n",
    "print(\"Sequential 输出:\", net(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
