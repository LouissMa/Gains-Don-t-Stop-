{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19afc0fb",
   "metadata": {},
   "source": [
    "模型参数的访问、初始化和共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e6236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "net = nn.Sequential(nn.Linear(4, 3), nn.ReLU(), nn.Linear(3, 1)) #\n",
    "print(net)\n",
    "X = torch.rand(2, 4)\n",
    "Y = net(X).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f4203",
   "metadata": {},
   "source": [
    "1.访问模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f82d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "0.weight torch.Size([3, 4])\n",
      "0.bias torch.Size([3])\n",
      "2.weight torch.Size([1, 3])\n",
      "2.bias torch.Size([1])\n",
      "weight torch.Size([3, 4]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias torch.Size([3]) <class 'torch.nn.parameter.Parameter'>\n",
      "weight1\n",
      "tensor([[ 0.2695, -0.1191,  0.1470,  0.4575],\n",
      "        [ 0.3044, -0.2531,  0.1825,  0.0920],\n",
      "        [-0.1740, -0.1391,  0.1717, -0.1503]])\n",
      "None\n",
      "tensor([[ 0.1623,  0.1111,  0.1144,  0.1902],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1541, -0.1055, -0.1086, -0.1807]])\n"
     ]
    }
   ],
   "source": [
    "#访问模型参数：named_parameters()\n",
    "print(type(net.named_parameters()))  # 类型检查\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())  # 打印名称和形状\n",
    "for name, param in net[0].named_parameters():\n",
    "    print(name, param.size(), type(param))  # 单层参数 + 类型\n",
    "#MyModel示例：Parameter vs. Tensor\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "        self.weight1 = nn.Parameter(torch.rand(20, 20))  # Parameter（注册）\n",
    "        self.weight2 = torch.rand(20, 20)  # 普通Tensor（不注册）\n",
    "    def forward(self, x):\n",
    "        pass  # 空，焦点参数\n",
    "\n",
    "n = MyModel()\n",
    "for name, param in n.named_parameters():\n",
    "    print(name)  # 只print weight1\n",
    "#访问data和grad\n",
    "# 访问data和grad\n",
    "weight_0 = list(net[0].named_parameters())[0]  # 取第一个参数 (name, param) 元组\n",
    "print(weight_0[1].data)  # 数据值 - 修正：使用[1]获取参数对象\n",
    "print(weight_0[1].grad)  # 梯度 (初始None) - 修正：使用[1]获取参数对象\n",
    "Y.backward()  # 反向传播\n",
    "print(weight_0[1].grad)  # 梯度值 - 修正：使用[1]获取参数对象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867de42",
   "metadata": {},
   "source": [
    "2.初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21104305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.bias tensor([-0.0982])\n",
      "2.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.normal_(param, mean=0, std=0.01)  # 初始化为N(0,0.01)\n",
    "print(name, param.data)  # 打印name和值\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        init.constant_(param, val=0)  # 初始化为常数0\n",
    "print(name, param.data)  # 打印name和值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a630f3",
   "metadata": {},
   "source": [
    "3.⾃自定义初始化⽅方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c610a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[ 0.0000,  9.1267,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -6.9104, -0.0000],\n",
      "        [ 0.0000,  6.4669, -0.0000, -5.5608]])\n",
      "2.weight tensor([[ 0.0000, -9.0757,  0.0000]])\n",
      "0.bias tensor([1., 1., 1.])\n",
      "2.bias tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "def normal_(tensor, mean=0, std=1):\n",
    "    with torch.no_grad():\n",
    "        return tensor.normal_(mean, std)\n",
    "    \n",
    "def init_weight_(tensor):\n",
    "    with torch.no_grad():\n",
    "        # 第一步：在[-10, 10]范围内均匀分布初始化\n",
    "        tensor.uniform_(-10, 10)\n",
    "        # 第二步：将绝对值小于5的值置为0\n",
    "        tensor *= (tensor.abs() >= 5).float()\n",
    "# 遍历网络所有参数\n",
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:  # 只对权重参数应用\n",
    "        init_weight_(param)\n",
    "        print(name, param.data)\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if 'bias' in name:  # 对偏置参数加1\n",
    "        param.data += 1  # 直接操作.data，不影响计算图\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cef8c3",
   "metadata": {},
   "source": [
    "4.共享模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01712441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=1, bias=False)\n",
      "  (1): Linear(in_features=1, out_features=1, bias=False)\n",
      ")\n",
      "0.weight tensor([[3.]])\n",
      "True\n",
      "True\n",
      "tensor(9., grad_fn=<SumBackward0>)\n",
      "tensor([[6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "# 创建单个线性层实例\n",
    "linear = nn.Linear(1, 1, bias=False)\n",
    "# 在Sequential中重复使用同一个实例\n",
    "net = nn.Sequential(linear, linear)\n",
    "\n",
    "print(net)\n",
    "for name, param in net.named_parameters():\n",
    "    init.constant_(param, val=3)\n",
    "    print(name, param.data)\n",
    "# 输出: weight tensor([[3.]])\n",
    "\n",
    "# 验证是同一个对象\n",
    "print(id(net[0]) == id(net[1]))          # True - 是同一个层实例\n",
    "print(id(net[0].weight) == id(net[1].weight))  # True - 是同一个参数张量\n",
    "\n",
    "x = torch.ones(1, 1)\n",
    "y = net(x).sum()\n",
    "print(y)  # 计算过程: x -> linear -> linear -> sum()\n",
    "# 输出: tensor(9., grad_fn=<SumBackward0>)\n",
    "# 计算过程: 3*1 = 3 -> 3*3 = 9\n",
    "\n",
    "y.backward()\n",
    "print(net[0].weight.grad)  # 单次梯度是3，两次所以就是6\n",
    "# 输出: tensor([[6.]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
