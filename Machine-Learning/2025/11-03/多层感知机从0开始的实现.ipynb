{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4cf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import sys\n",
    "import d2l.torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e03a4",
   "metadata": {},
   "source": [
    "1.获取与读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8badb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "num_inputs,num_outputs,num_hiddens = 784, 10, 256\n",
    "W1 = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_hiddens)), dtype=torch.float)\n",
    "b1 = torch.zeros(num_hiddens, dtype=torch.float)\n",
    "W2 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_outputs)), dtype=torch.float)\n",
    "b2 = torch.zeros(num_outputs, dtype=torch.float)\n",
    "params = [W1, b1, W2, b2]\n",
    "for param in params:\n",
    "    param.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a1806",
   "metadata": {},
   "source": [
    "2.定义激活函数 && 定义模型 && 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d5c9dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0031, train acc 0.709, test acc 0.742\n",
      "epoch 2, loss 0.0019, train acc 0.822, test acc 0.839\n",
      "epoch 3, loss 0.0017, train acc 0.844, test acc 0.835\n",
      "epoch 4, loss 0.0015, train acc 0.855, test acc 0.832\n",
      "epoch 5, loss 0.0015, train acc 0.863, test acc 0.842\n"
     ]
    }
   ],
   "source": [
    "def relu(X):\n",
    "    return torch.max(input=X, other=torch.tensor(0.0))\n",
    "#定义模型\n",
    "def net(X):\n",
    "    X = X.view((-1, num_inputs))  # 展平\n",
    "    H = relu(torch.matmul(X, W1) + b1)  # 隐藏层\n",
    "    return torch.matmul(H, W2) + b2  # 输出层\n",
    "#定义损失函数\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "#训练模型\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"小批量随机梯度下降算法\"\"\"\n",
    "    if lr is None or batch_size is None:\n",
    "        raise ValueError(\"学习率(lr)和批量大小(batch_size)不能为None\")\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            if param.grad is not None:\n",
    "                param -= lr * param.grad / batch_size\n",
    "\n",
    "def train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params=None,lr=None,optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X,y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat,y).sum()\n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params,lr,batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'% (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "num_epochs, lr = 5, 100.0\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs,batch_size, params, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
